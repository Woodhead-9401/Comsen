## 12.14 YOLO实践报告
1. 环境配置：
详情见`requirements.txt`
2. 预训练模型效果：
![alt text](task1_results/detection_result_1.jpg)
更多可见`task1_results`文件夹
3. 视频/摄像头检测的演示：
详情见`task2_results`,里面包含一个电脑自带摄像头的实时监测的小视频，以及自己画了一个矩形运动的视频
4. 自定义数据集上的训练
* 本次实验使用了==COCO2017数据集==的一部分，具体配置文件为`coco_subset.yaml`,具体操作时注意修改Task3内和数据集配置文件中的完整COCO数据集的相对路径。使用顺序为`prepare->check->train->evaluate->inference`
* 本次实验中选取了`[person, car, dog]`这三个类别，更加详细的一些具体训练参数在`runs`当中,注意到狗的训练数目偏少，这是由于`COCO`数据集本身的原因导致的，本身`COCO`数据集人的比例就远远多于车辆和狗
==================================================
* 模型评估结果:
mAP50 (IoU=0.5): 0.6097
mAP50-95: 0.3887
各个类别的AP50:
  person: 0.6854
  car: 0.5655
  dog: 0.5782
* Train
   Class Images Instances  Box(PR mAP50  mAP50-95): 
    all   200      904      0.641      0.498      0.511      0.306
    person        186        749      0.709      0.544      0.623      0.382
    car         38        145      0.622      0.366      0.439       0.26
    dog          8         10      0.593      0.584       0.47      0.274
5. 学习笔记
##### 一、YOLO原理的理解
* YOLO（You Only Look Once）的核心理念是将目标检测视为一个端到端的回归问题，与传统两阶段检测器（如R-CNN系列）相比，最大的优势在于速度。
关键创新点：
* 单阶段检测：仅通过一次前向传播就能同时预测所有边界框和类别概率
* 网格划分：将输入图像划分为S×S的网格，每个网格负责预测其中心点落在该网格内的目标
* 多尺度预测：现代YOLO版本（v3以后）引入了多尺度预测，有效解决了不同大小目标的检测问题
#####　二、遇到的问题与经验总结
* 无法登上ROBOFLOW，浪费大量时间在某池寻找数据集，但是结果图片又有诸多问题，无法使用，最后使用Kaggle才解决该问题
* YOLO十分迅速便捷，操作十分简便，容易做出成果